{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Part of a graveyard dating back around 3,400 years has been unearthed in southern Egypt at the site of Gebel el Silsila, Egypt's antiquities ministry has announced.\n",
    "The discovery was made by a team from Sweden's Lund University, led by researcher Maria Nilsson. Previously, the Lund University researchers had uncovered part of the cemetery during their 2015-2016 field season, \n",
    "and their more recent work in the 2016-2017 field season has revealed more of it, according to a statement from the ministry. [See Photos of the Crypts Discovered at Gebel el Silsila]\n",
    "The tombs range in size from large crypts that may hold the bones of complete families to smaller tombs that are sometimes little more than shallow graves with a few stones on top. \n",
    "Children and infants were found in some of the simpler graves. Two of the children were buried \"within the overhangs of the natural sandstone bluffs,\" Nasr Salama, an archaeologist with the antiquities ministry who is general \n",
    "director of Aswan antiquities, said in the statement.\n",
    "An analysis of the skeletons found in the cemetery revealed that, in their lifetimes, the people buried there performed jobs that involved a heavy amount of manual labor and high risk of accidents.\n",
    "\"Fractures of the long bones and increased muscle attachments amongst the skeletal remains indicate behaviors related to occupational hazards and an extremely labor-intensive environment,\" Nilsson said.\n",
    "However, although they performed hard labor, those individuals also appear to have had access to decent food and medical care. So far, little evidence for malnutrition has been found among the skeletal remains, and\n",
    " \"many of the injuries appear to be in an advanced stage of healing, suggesting effective medical care,\" Nilsson said in the statement.\n",
    "The researchers also found evidence of the food the people would have consumed and some of the resources accessible to them.\n",
    "\"Fossils of sheep and goats, as well as a couple of Nile perch and almost complete crocodile, were found along with sandstone sarcophagi, sculptured and occasionally painted pottery coffins, \n",
    "painted cartonnage [a material used in creating mummy masks and some types of coffins], textile and organic wrapping, ceramic vessels and plates, as well as an array of jewelry, \n",
    "amulets and scarabs [artifacts shaped like a scarab beetle that sometimes contain writing],\" Nilsson said.\n",
    "At least one amulet shows an image of Bes, a googly-eyed god that the ancient Egyptians believed could protect children and pregnant mothers from evil forces, Nilsson added.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set (stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(text)\n",
    "\n",
    "freqTable = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in words:\n",
    "  word = word.lower()\n",
    "  if word in stopwords:\n",
    "    continue\n",
    "    \n",
    "  if word in freqTable:\n",
    "    freqTable[word] += 1\n",
    "  else:\n",
    "    freqTable[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(text)\n",
    "\n",
    "sentenceScore = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in sentences:\n",
    "  for word, freq in freqTable.items():\n",
    "    if word in sentence.lower():\n",
    "      if sentence in sentenceScore:\n",
    "        sentenceScore[sentence] += freq\n",
    "      else:\n",
    "        sentenceScore[sentence] = freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So far, little evidence for malnutrition has been found among the skeletal remains, and\n",
      " \"many of the injuries appear to be in an advanced stage of healing, suggesting effective medical care,\" Nilsson said in the statement.\"Fossils of sheep and goats, as well as a couple of Nile perch and almost complete crocodile, were found along with sandstone sarcophagi, sculptured and occasionally painted pottery coffins, \n",
      "painted cartonnage [a material used in creating mummy masks and some types of coffins], textile and organic wrapping, ceramic vessels and plates, as well as an array of jewelry, \n",
      "amulets and scarabs [artifacts shaped like a scarab beetle that sometimes contain writing],\" Nilsson said.\n"
     ]
    }
   ],
   "source": [
    "sumValue = 0\n",
    "for sentence in sentenceScore:\n",
    "  sumValue += sentenceScore[sentence]\n",
    "\n",
    "avg =  int(sumValue / len(sentenceScore))\n",
    "\n",
    "\n",
    "\n",
    "#summary\n",
    "\n",
    "summary = \"\"\n",
    "\n",
    "for sentence in sentences:\n",
    "  if (sentence in sentenceScore) and (sentenceScore[sentence] > (1.2*avg)):\n",
    "    summary += \"\" + sentence\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\babba\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\babba\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\babba\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\babba\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\babba\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\babba\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\babba\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\babba\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\babba\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\babba\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\babba\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\babba\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Neither PyTorch nor TensorFlow >= 2.0 have been found.Models won't be available and only tokenizers, configurationand file/data utilities can be used.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AlbertModel' from 'transformers' (C:\\Users\\babba\\Anaconda3\\lib\\site-packages\\transformers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-7cb8f3f2ef0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msummarizer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSummarizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTransformerSummarizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\summarizer\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msummarizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbert\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSummarizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTransformerSummarizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0m__all__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"Summarizer\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"TransformerSummarizer\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\summarizer\\bert.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m from transformers import (AlbertModel, AlbertTokenizer, BartModel, BigBirdModel, BigBirdTokenizer,\n\u001b[0m\u001b[0;32m      5\u001b[0m                           \u001b[0mBartTokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                           \u001b[0mCamembertModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCamembertTokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCTRLModel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'AlbertModel' from 'transformers' (C:\\Users\\babba\\Anaconda3\\lib\\site-packages\\transformers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from summarizer import Summarizer,TransformerSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
